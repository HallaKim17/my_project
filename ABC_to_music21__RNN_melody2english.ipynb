{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = m.converter.parse('./data/nottingham_database/reelsA-C.abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<music21.stream.Score 0x11b5d7b50>\n",
      "[<music21.pitch.Pitch A5>, <music21.pitch.Pitch F#5>, <music21.pitch.Pitch G5>, <music21.pitch.Pitch F#5>, <music21.pitch.Pitch E5>, <music21.pitch.Pitch D5>, <music21.pitch.Pitch C#5>, <music21.pitch.Pitch B4>, <music21.pitch.Pitch A4>, <music21.pitch.Pitch F#5>, <music21.pitch.Pitch G5>, <music21.pitch.Pitch B4>, <music21.pitch.Pitch C#5>, <music21.pitch.Pitch B4>, <music21.pitch.Pitch C#5>, <music21.pitch.Pitch D5>, <music21.pitch.Pitch A4>, <music21.pitch.Pitch G4>, <music21.pitch.Pitch F#4>, <music21.pitch.Pitch E4>, <music21.pitch.Pitch F#4>, <music21.pitch.Pitch A4>, <music21.pitch.Pitch A4>, <music21.pitch.Pitch G4>, <music21.pitch.Pitch F#4>, <music21.pitch.Pitch G4>, <music21.pitch.Pitch B4>, <music21.pitch.Pitch B4>, <music21.pitch.Pitch B4>, <music21.pitch.Pitch C#5>, <music21.pitch.Pitch D5>, <music21.pitch.Pitch E5>, <music21.pitch.Pitch C#5>, <music21.pitch.Pitch D5>, <music21.pitch.Pitch E5>, <music21.pitch.Pitch C#5>, <music21.pitch.Pitch B4>, <music21.pitch.Pitch C#5>, <music21.pitch.Pitch A4>, <music21.pitch.Pitch D5>, <music21.pitch.Pitch E5>, <music21.pitch.Pitch F#5>, <music21.pitch.Pitch E5>, <music21.pitch.Pitch F#5>, <music21.pitch.Pitch D5>, <music21.pitch.Pitch E5>, <music21.pitch.Pitch F#5>, <music21.pitch.Pitch G5>, <music21.pitch.Pitch F#5>, <music21.pitch.Pitch G5>, <music21.pitch.Pitch E5>, <music21.pitch.Pitch F#5>, <music21.pitch.Pitch G5>, <music21.pitch.Pitch A5>, <music21.pitch.Pitch B4>, <music21.pitch.Pitch C#5>, <music21.pitch.Pitch B4>, <music21.pitch.Pitch C#5>, <music21.pitch.Pitch D5>, <music21.pitch.Pitch D5>]\n"
     ]
    }
   ],
   "source": [
    "##### how to extract melodies in abc format ######\n",
    "\n",
    "print(a[0])\n",
    "len(a.elements) # 'reelsA-C.abc' 안에 81곡 포함 (abc파일은 보통 한 파일 안에 여러 곡이 들어있음)\n",
    "a[0].elements # Elements of the 1st score\n",
    "#print(a[0].flat.notes.stream().show('text')) # notes and chordsymbol of 1st score\n",
    "print(a[0].flat.getElementsByClass('Note').pitches) # extract melodies in 1st score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A5', 'F#5', 'G5', 'F#5', 'E5', 'D5', 'C#5', 'B4', 'A4', 'F#5', 'G5', 'B4', 'C#5', 'B4', 'C#5', 'D5', 'A4', 'G4', 'F#4', 'E4', 'F#4', 'A4', 'A4', 'G4', 'F#4', 'G4', 'B4', 'B4', 'B4', 'C#5', 'D5', 'E5', 'C#5', 'D5', 'E5', 'C#5', 'B4', 'C#5', 'A4', 'D5', 'E5', 'F#5', 'E5', 'F#5', 'D5', 'E5', 'F#5', 'G5', 'F#5', 'G5', 'E5', 'F#5', 'G5', 'A5', 'B4', 'C#5', 'B4', 'C#5', 'D5', 'D5']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "all_songs_notes = [song.flat.getElementsByClass('Note').pitches for song in songs]\n",
    "notes = [[pitch.nameWithOctave for pitch in song_notes] for song_notes in all_songs_notes]\n",
    "print(notes[0]) # melody notes of 1st score \n",
    "unique_notes = list(set(sum(notes, [])))\n",
    "print(len(unique_notes)) # number of unique_notes in all 81 scores in reelA-C.abc file: 30\n",
    "print(len(sum(notes, []))) # number of total notes in all 81 scores in reelA-C.abc file: 7813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D5', 'A4', 'B4', 'E5', 'G4', 'F#5', 'C#5', 'C5', 'G5', 'F#4', 'A5', 'E4', 'D4', 'G#4', 'B5', 'G#5', 'F5', 'F4', 'B-4', 'C#4', 'C4', 'A3', 'E#5', 'B3', 'D#5', 'B-5', 'A#4', 'G3', 'D-5', 'F-5']\n",
      "{'D5': 0, 'A4': 1, 'B4': 2, 'E5': 3, 'G4': 4, 'F#5': 5, 'C#5': 6, 'C5': 7, 'G5': 8, 'F#4': 9, 'A5': 10, 'E4': 11, 'D4': 12, 'G#4': 13, 'B5': 14, 'G#5': 15, 'F5': 16, 'F4': 17, 'B-4': 18, 'C#4': 19, 'C4': 20, 'A3': 21, 'E#5': 22, 'B3': 23, 'D#5': 24, 'B-5': 25, 'A#4': 26, 'G3': 27, 'D-5': 28, 'F-5': 29}\n"
     ]
    }
   ],
   "source": [
    "note_freq = dict(Counter(sum(notes, [])))\n",
    "note_freq = sorted(note_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "idx2note = [item[0] for item in note_freq]\n",
    "note2idx = {item[0]:note_freq.index(item) for item in note_freq}\n",
    "print(idx2note)\n",
    "print(note2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 't', 'a', 'o', 'i', 'n', 's', 'r', 'h', 'l', 'd', 'c', 'u', 'm', 'g', 'f', 'p', 'w', 'y', 'b', ',', '.', 'v', 'k', '-', 'x', '0', 'j', 'q', 'z']\n",
      "{'e': 0, 't': 1, 'a': 2, 'o': 3, 'i': 4, 'n': 5, 's': 6, 'r': 7, 'h': 8, 'l': 9, 'd': 10, 'c': 11, 'u': 12, 'm': 13, 'g': 14, 'f': 15, 'p': 16, 'w': 17, 'y': 18, 'b': 19, ',': 20, '.': 21, 'v': 22, 'k': 23, '-': 24, 'x': 25, '0': 26, 'j': 27, 'q': 28, 'z': 29}\n"
     ]
    }
   ],
   "source": [
    "idx2char = ['e','t','a','o','i','n','s','r','h','l','d','c','u','m','g','f','p',\n",
    "            'w','y','b',',','.','v','k','-','x','0','j','q','z'] # source: https://mdickens.me/typing/letter_frequency.html\n",
    "char2idx = {ch:idx2char.index(ch) for ch in idx2char}\n",
    "print(idx2char)\n",
    "print(char2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 100\n",
    "input_size = 30\n",
    "hidden_size = 10\n",
    "output_size = 30\n",
    "seq_length = 4\n",
    "num_layers = 2\n",
    "num_directions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7809\n",
      "7809\n",
      "[[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])], [array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]]\n",
      "[3, 0]\n"
     ]
    }
   ],
   "source": [
    "one_hot_lookup = np.eye(len(unique_notes))\n",
    "one_hot_note = [one_hot_lookup[note2idx[note]] for note in sum(notes, [])]\n",
    "X = [one_hot_note[i:i+4] for i in range(len(one_hot_note)-4)]\n",
    "Y = [one_hot_note[i+4] for i in range(len(one_hot_note)-4)]\n",
    "Y = [list(one_hot).index(1) for one_hot in Y]\n",
    "\n",
    "print(len(X)) # 7809 \n",
    "print(len(Y)) # 7809 total training samples\n",
    "print(X[:2])\n",
    "print(Y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(X, Y, batch_size):\n",
    "    X_ = X.copy()\n",
    "    Y_ = Y.copy()\n",
    "    samples = list(zip(X_,Y_))\n",
    "    random.shuffle(samples)\n",
    "    batch = random.sample(samples, batch_size)\n",
    "    [input_batch, target_batch] = list(zip(*batch))\n",
    "    input_batch = torch.tensor(input_batch, dtype=torch.float32)\n",
    "    target_batch = torch.tensor(target_batch, dtype=torch.int64)\n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.seq_length = seq_length\n",
    "        self.num_layers = num_layers\n",
    "        self.num_directions = num_directions\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.input_size, self.hidden_size, num_layers=self.num_layers, bidirectional=True, \n",
    "                          batch_first=True)\n",
    "        self.fc1 = nn.Linear(self.hidden_size, self.output_size, bias=True)\n",
    "        self.fc2 = nn.Linear(self.num_directions*self.num_layers*self.output_size, self.output_size, bias=True)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers*self.num_directions, self.batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "    \n",
    "    def forward(self, X, hidden):\n",
    "        X = X.view(-1, self.seq_length, self.input_size)\n",
    "        outputs, (hidden, cell) = self.rnn(X, hidden)\n",
    "        #print(\"rnn outputs: \", outputs.size(), \"rnn last hidden: \", hidden.size())\n",
    "        fc1_output = self.fc1(hidden)\n",
    "        #print(\"fc1 output: \", fc1_output.size())\n",
    "        fc1_output = torch.transpose(fc1_output, 0,1)\n",
    "        fc1_output = fc1_output.reshape(-1, self.num_directions*self.num_layers*self.output_size)\n",
    "        fc2_output = self.fc2(fc1_output)\n",
    "        #print(\"fc2 output: \", fc2_output.size())\n",
    "        return fc2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100 | loss: 2.527\n",
      "input_batch:  torch.Size([100, 4, 30]) pred:  torch.Size([100, 30]) target_batch:  torch.Size([100])\n",
      "epoch: 200 | loss: 2.251\n",
      "input_batch:  torch.Size([100, 4, 30]) pred:  torch.Size([100, 30]) target_batch:  torch.Size([100])\n",
      "epoch: 300 | loss: 2.163\n",
      "input_batch:  torch.Size([100, 4, 30]) pred:  torch.Size([100, 30]) target_batch:  torch.Size([100])\n",
      "epoch: 400 | loss: 2.029\n",
      "input_batch:  torch.Size([100, 4, 30]) pred:  torch.Size([100, 30]) target_batch:  torch.Size([100])\n",
      "epoch: 500 | loss: 2.011\n",
      "input_batch:  torch.Size([100, 4, 30]) pred:  torch.Size([100, 30]) target_batch:  torch.Size([100])\n",
      "epoch: 600 | loss: 2.004\n",
      "input_batch:  torch.Size([100, 4, 30]) pred:  torch.Size([100, 30]) target_batch:  torch.Size([100])\n",
      "epoch: 700 | loss: 1.871\n",
      "input_batch:  torch.Size([100, 4, 30]) pred:  torch.Size([100, 30]) target_batch:  torch.Size([100])\n",
      "epoch: 800 | loss: 1.965\n",
      "input_batch:  torch.Size([100, 4, 30]) pred:  torch.Size([100, 30]) target_batch:  torch.Size([100])\n",
      "epoch: 900 | loss: 1.910\n",
      "input_batch:  torch.Size([100, 4, 30]) pred:  torch.Size([100, 30]) target_batch:  torch.Size([100])\n",
      "epoch: 1000 | loss: 1.738\n",
      "input_batch:  torch.Size([100, 4, 30]) pred:  torch.Size([100, 30]) target_batch:  torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    input_batch, target_batch = make_batch(X,Y,batch_size)\n",
    "    #print(\"input_batch: \", input_batch.size(), \"target_batch: \", target_batch.size())\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    hidden = model.init_hidden()\n",
    "    cell = model.init_hidden()\n",
    "    pred = model.forward(input_batch, (hidden,cell))\n",
    "    #print(pred.size(), target_batch.size())\n",
    "    pred = pred.view(-1, model.output_size)\n",
    "    target_batch = target_batch.view(model.batch_size)\n",
    "    \n",
    "    loss = criterion(pred, target_batch)\n",
    "    \n",
    "    value, idx = pred.data.max(dim=1)\n",
    "    predicted = [idx2note[x] for x in idx.numpy()]\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        \n",
    "        batch_note = []\n",
    "        for input_ in input_batch:\n",
    "            one_batch_notes = [idx2note[list(note).index(1)] for note in input_]\n",
    "            batch_note.append(one_batch_notes)\n",
    "            \n",
    "        #print(\"epoch: %d | loss: %1.3f\" % (epoch+1, loss), \"| pred: \", list(zip(batch_note, predicted)))\n",
    "        print(\"epoch: %d | loss: %1.3f\" % (epoch+1, loss))\n",
    "        print(\"input_batch: \", input_batch.size(), \"pred: \", pred.size(), \"target_batch: \", target_batch.size())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  hellittatithnoeoetatiearatiarhlhdithdheoesteotttrtilie\n"
     ]
    }
   ],
   "source": [
    "input_seed = ['h','e','l','l']\n",
    "input_one_hot = [char2idx[ch] for ch in input_seed]\n",
    "input_one_hot = [one_hot_lookup[x] for x in input_one_hot]\n",
    "generation = input_one_hot.copy()\n",
    "input_one_hot_tensor = torch.tensor([input_one_hot], dtype=torch.float32)\n",
    "#print(input_one_hot_tensor.size())\n",
    "\n",
    "generation_time = 50\n",
    "\n",
    "for i in range(generation_time):\n",
    "    test_hidden = torch.randn(model.num_layers*model.num_directions, 1, model.hidden_size)\n",
    "    test_cell = torch.randn(model.num_layers*model.num_directions, 1, model.hidden_size)\n",
    "    char_output = model.forward(input_one_hot_tensor, (test_hidden, test_cell))\n",
    "    char_output = char_output.view(-1, model.output_size)\n",
    "    #print(char_output, char_output.size())\n",
    "    \n",
    "    value, idx = char_output.data.max(dim=1)\n",
    "    next_input = one_hot_lookup[int(idx.squeeze())]\n",
    "    generation.append(next_input)\n",
    "    input_one_hot_tensor = generation[-4:]\n",
    "    input_one_hot_tensor = torch.tensor([input_one_hot_tensor], dtype=torch.float32)\n",
    "    #print(input_one_hot_tensor.size())\n",
    "    \n",
    "predicted_char = [idx2char[list(one_hot).index(1)] for one_hot in generation]\n",
    "print('predicted: ', ''.join(predicted_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 2.0000, 3.0000],\n",
      "         [0.1000, 0.2000, 0.3000]],\n",
      "\n",
      "        [[4.0000, 5.0000, 6.0000],\n",
      "         [0.4000, 0.5000, 0.6000]]])\n",
      "torch.Size([2, 2, 3])\n",
      "3\n",
      "tensor([[[1.0000, 2.0000, 3.0000],\n",
      "         [4.0000, 5.0000, 6.0000]],\n",
      "\n",
      "        [[0.1000, 0.2000, 0.3000],\n",
      "         [0.4000, 0.5000, 0.6000]]])\n",
      "tensor([[1.0000, 2.0000, 3.0000, 4.0000, 5.0000, 6.0000],\n",
      "        [0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1,2,3],[0.1,0.2,0.3]],[[4,5,6],[0.4,0.5,0.6]]])\n",
    "print(a)\n",
    "print(a.size())\n",
    "print(a.size()[2])\n",
    "b = torch.transpose(a, 0,1)\n",
    "print(b)\n",
    "print(b.reshape(2,-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_jupyter",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
